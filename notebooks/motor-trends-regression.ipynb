{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Trend Car Road Test Regression Problem\n",
    "The data was extracted from the 1974 Motor Trend US magazine and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973--74 models).\n",
    "\n",
    "We form a regression problem by predicting the MPG of a car from its other features.\n",
    "\n",
    "*This notebooks compares regression performance for different models on a Leave-One-Out Cross-Validation of the motor trend car test data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Motor Trend Car Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mtcars.csv', header=0)\n",
    "df = df.drop(columns=[\"model\"]) # Not used in regression\n",
    "X = np.array(df.iloc[:,1:].values, dtype=float)\n",
    "y = np.array(df.iloc[:,0].values, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Data\n",
    "We normalize across the full feature matrix since both X_train and X_test would be available when we train our model.\n",
    "\n",
    "For the target values, we center when we compute the leave-one-out split and only use the training data to treat y_test as unknown.\n",
    "\n",
    "Note: The PCA transformation has no effect on least-squares or ridge regression models with a single regularizer, but it is significant when using multiple regularizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "X = PCA().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-fitted ridge regresson parameters\n",
    "A second order optimizer was used to fit ridge regression to the generated regression problems so as to minize the LOOCV and GCV for 1 and p regularization parameters on each leave-one-out training matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv_1_params = np.loadtxt('mtcars-loocv-1-params.txt')\n",
    "loocv_p_params = np.loadtxt('mtcars-loocv-p-params.txt')\n",
    "gcv_1_params = np.loadtxt('mtcars-gcv-1-params.txt')\n",
    "gcv_p_params = np.loadtxt('mtcars-gcv-p-params.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a Leave-One-Out Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_leave_one_out_split(X, y, index):\n",
    "    num_data = len(y)\n",
    "    train_indexes = list(range(index)) + list(range(index+1, num_data))\n",
    "    test_indexes = [index]\n",
    "    X_train, y_train = X[train_indexes, :], y[train_indexes]\n",
    "    X_test, y_test = X[test_indexes, :], y[test_indexes]\n",
    "    y_mean = np.mean(y_train)\n",
    "    y_train -= y_mean\n",
    "    y_test -= y_mean\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Loaded Ridge Regression Parameters Represent for CV Optimums\n",
    "For each leave-one-out training dataset, we verify that the loaded ridge regression parameters supply a minimum of the LOOCV error by walking to neighboring parameters and confirming that we don't find one that's significantly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loocv(X, y, D):\n",
    "    A = np.dot(np.conj(X.T), X) + D\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    b_hat = np.dot(A_inv, np.dot(np.conj(X.T), y))\n",
    "    y_hat = np.dot(X, b_hat)\n",
    "    h = np.array([np.dot(x_i.conj(), np.dot(A_inv, x_i)).real for x_i in X])\n",
    "    return np.sum((np.abs(y - y_hat) / (1 - h))**2) / len(y)\n",
    "\n",
    "def verify_loocv_opt_1(X, y, alpha):\n",
    "    delta_x = 1.0e-3\n",
    "    def f(x):\n",
    "        return compute_loocv(X, y, np.identity(X.shape[1])*x)\n",
    "    f0 = f(alpha)\n",
    "    for x in [alpha-delta_x, alpha+delta_x]:\n",
    "        x = np.abs(x)\n",
    "        delta_y = f(x) - f0\n",
    "        relative_delta_y = delta_y / delta_x\n",
    "        if relative_delta_y < 0 and np.abs(relative_delta_y) > 1.0e-3:\n",
    "            assert False, \"can't verify optimum\"\n",
    "\n",
    "def verify_loocv_opt_p(X, y, alpha):\n",
    "    delta_x = 1.0e-3\n",
    "    for i, alpha_i in enumerate(alpha):\n",
    "        def f(x):\n",
    "            alpha_copy = np.array(alpha)\n",
    "            alpha_copy[i] = x\n",
    "            return compute_loocv(X, y, np.diag(alpha_copy))\n",
    "        f0 = f(alpha_i)\n",
    "        for x in [alpha_i - delta_x, alpha_i + delta_x]:\n",
    "            x = np.abs(x)\n",
    "            delta_y = f(x) - f0\n",
    "            relative_delta_y = delta_y / delta_x\n",
    "            if relative_delta_y < 0 and np.abs(relative_delta_y) > 1.0e-3:\n",
    "                assert False, \"can't verify optimum\"\n",
    "\n",
    "for index in range(len(y)):\n",
    "    X_train, y_train, _, _ = compute_leave_one_out_split(X, y, index)\n",
    "    verify_loocv_opt_1(X_train, y_train, loocv_1_params[index])\n",
    "    verify_loocv_opt_p(X_train, y_train, loocv_p_params[index])\n",
    "    U, S, Vt = np.linalg.svd(X_train)\n",
    "    n = len(y_train)\n",
    "    W = [[np.exp(2j*np.pi*i*j / n) / np.sqrt(n) for j in range(n)] for i in range(n)]\n",
    "    Q = np.dot(W, U.T)\n",
    "    X_train_prime = np.dot(Q, X_train)\n",
    "    y_train_prime = np.dot(Q, y_train)\n",
    "    verify_loocv_opt_1(X_train_prime, y_train_prime, gcv_1_params[index])\n",
    "    verify_loocv_opt_p(X_train_prime, y_train_prime, gcv_p_params[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ridge_regression(X, y, alpha):\n",
    "    if isinstance(alpha, float):\n",
    "        alpha = np.ones(X.shape[1])*alpha\n",
    "    A = np.dot(X.T, X) + np.diag(alpha)\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    return np.dot(A_inv, np.dot(X.T, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute LOOCV Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(model_name, index, X_train, y_train, X_test):\n",
    "    if model_name == \"LS\":\n",
    "        # Note: y was already centered during the leave-one-out split\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        return model.predict(X_test)\n",
    "    if model_name == \"RR-LOOCV-1\":\n",
    "        alpha = loocv_1_params[index]\n",
    "    elif model_name == \"RR-LOOCV-p\":\n",
    "        alpha = loocv_p_params[index]\n",
    "    elif model_name == \"RR-GCV-1\":\n",
    "        alpha = gcv_1_params[index]\n",
    "    elif model_name == \"RR-GCV-p\":\n",
    "        alpha = gcv_p_params[index]\n",
    "    else:\n",
    "        assert False, \"No such model\"\n",
    "    b_hat = fit_ridge_regression(X_train, y_train, alpha)\n",
    "    return np.dot(X_test, b_hat)\n",
    "loocv_errors = defaultdict(list)\n",
    "model_names = [\"LS\", \"RR-LOOCV-1\", \"RR-LOOCV-p\", \"RR-GCV-1\", \"RR-GCV-p\"]\n",
    "for index in range(len(y)):\n",
    "    X_train, y_train, X_test, y_test = compute_leave_one_out_split(X, y, index)\n",
    "    for model_name in model_names:\n",
    "        y_pred = fit_predict(model_name, index, X_train, y_train, X_test)\n",
    "        err = y_test - y_pred\n",
    "        loocv_errors[model_name].append(np.dot(err, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the RMSEs from the LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS         3.3806726635155115\n",
      "RR-LOOCV-1 2.7683583580082036\n",
      "RR-LOOCV-p 2.7735425552077224\n",
      "RR-GCV-1   2.7494763182212663\n",
      "RR-GCV-p   2.617569927618669\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(model_name.ljust(10), np.sqrt(np.mean(loocv_errors[model_name])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
